{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing anitSMASH outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, rename, path\n",
    "import pandas as pd\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up folder names from antiSMASH raw output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antismash_results = \"../antismash_results\"\n",
    "\n",
    "for assembly in listdir(antismash_results):\n",
    "    if assembly == \".DS_Store\":\n",
    "        continue\n",
    "    if assembly.endswith(\"_assembly\"):\n",
    "        new_name = assembly.replace(\"_assembly\", \"\")\n",
    "        current_path = path.join(antismash_results, assembly)\n",
    "        new_path = path.join(antismash_results, new_name)\n",
    "\n",
    "        if path.exists(new_path):\n",
    "            continue\n",
    "        else:\n",
    "            rename(current_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all BGC annotations from antiSMASH output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bgc_annos(assembly_path: str, assembly: str):\n",
    "    \"\"\" Extract annotations from each BGC predicted by antiSMASH \"\"\"\n",
    "\n",
    "    all_annos = []  # Master list to store annotations from all GenBank files\n",
    "\n",
    "    for file in listdir(assembly_path):\n",
    "        if \".region\" in file:\n",
    "            file_path = f\"{assembly_path}/{file}\"\n",
    "            \n",
    "            with open(file_path, \"r\") as gbk:\n",
    "                records = SeqIO.parse(gbk, \"genbank\")\n",
    "\n",
    "                for record in records:\n",
    "                    for feature in record.features:\n",
    "                        if feature.type == \"protocluster\":\n",
    "                            tmp_dict = {}\n",
    "                            tmp_dict[\"Position\"] = file.split(\".gbk\")[0]\n",
    "\n",
    "                            number = feature.qualifiers.get(\"protocluster_number\").pop()\n",
    "                            category = feature.qualifiers.get(\"category\").pop()\n",
    "                            product = feature.qualifiers.get(\"product\").pop()\n",
    "\n",
    "                            tmp_dict[\"Protocluster\"] = number\n",
    "                            tmp_dict[\"Category\"] = category\n",
    "                            tmp_dict[\"Product\"] = product\n",
    "                            \n",
    "                            references = []\n",
    "                            for q in feature.qualifiers:\n",
    "                                if q.endswith(\"product_classes\"):\n",
    "                                    references = feature.qualifiers.get(q, [])  # Get reference(s) if found\n",
    "                            \n",
    "                            if not references:\n",
    "                                references = [product]  # Default to product if no reference found\n",
    "\n",
    "                            for ref in references:\n",
    "                                new_entry = tmp_dict.copy()\n",
    "                                new_entry[\"Reference\"] = ref\n",
    "                                new_entry[\"Assembly\"] = assembly\n",
    "                                all_annos.append(new_entry)\n",
    "\n",
    "    if all_annos:\n",
    "        df = pd.DataFrame(all_annos)\n",
    "\n",
    "        column_order = [\"Assembly\", \"Position\", \"Protocluster\", \"Category\", \"Product\", \"Reference\"]\n",
    "        df = df[column_order]\n",
    "\n",
    "        # Save individual assembly BGC annotations\n",
    "        output_path = f\"{assembly_path}/{assembly}_bgc_annotations.csv\"\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    return None\n",
    "\n",
    "def process_all_folders(antismash_results_path: str):\n",
    "    \"\"\"Loops through all subdirectories in 'antismash_results' and processes them.\"\"\"\n",
    "    all_dfs = []  # List to collect all individual DataFrames\n",
    "\n",
    "    for assembly in listdir(antismash_results_path):\n",
    "        if assembly == \".DS_Store\":  # Skip system files (MacOS thing)\n",
    "            continue\n",
    "        \n",
    "        assembly_path = f\"{antismash_results_path}/{assembly}\"\n",
    "        df = extract_bgc_annos(assembly_path=assembly_path, assembly=assembly)\n",
    "\n",
    "        if df is not None:\n",
    "            all_dfs.append(df)  # Store DataFrame if it's not empty\n",
    "\n",
    "    # Merge all DataFrames into one\n",
    "    if all_dfs:\n",
    "        merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        merged_df.to_csv(f\"{antismash_results_path}/all_bgc_annotations.csv\", index=False)\n",
    "        return merged_df\n",
    "\n",
    "    return \"No BGC annotations found in any assembly!\"\n",
    "\n",
    "# Run the processing\n",
    "antismash_results = \"../antismash_results\"\n",
    "merged_annotations = process_all_folders(antismash_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
